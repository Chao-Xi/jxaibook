# 1 AWS AI 词汇表

### 1 Attention

对于 AI 来说，注意力就好比你给某处打光，告诉模型什么是重要的，它需要特别注意什么。(Attention Is All You Need)

**转换器只需要通过注意力机制就可以处理序列数据，并不需要传统复发的或者回旋神经网络**。注意力机制使得模型能够权衡不同信息的重要度，这一技术在最先进的大语言模型应用中，如翻译、总结、以及文本生成，都有一席之地。

### 2 代表 Amazon Bedrock 服务

Amazon Bedrock 是亚马逊云科技的一项全托管服务，可以通过基础模型帮助你打造和规模化自己的 AI 应用

Bedrock 中提供了多种基础模型，包括三方模型，如一些 AI 行业新崛起的公司包括 AI21 Labs、Anthropic、Cohere、和 Stability AI。

选择一个基础模型后，你可以利用自己的数据对模型进行定制化，之后将这些模型整合部署到你通过其他亚马逊云科技的工具打造的应用中。

### 3 Amazon CodeWhisperer 服务

Amazon CodeWhisperer 是一个 AI 驱动的编程辅助服务。CodeWhisperer 是基于几十上百亿行代码（来源包括亚马逊和开源代码）训练的大语言模型，可以在你的集成开发环境（IDE）实时生成精准、安全的代码建议

### 4 扩散模型（Diffusion Models）

扩散模型也是生成式 AI 模型的一种，它们可以用来创造各种现实的图片或者其他数据。扩散模型很有趣的一点就是它们的工作原理是通过预言“噪声”、去除噪声、从含噪声的信息源中给出一个无噪声的结果。

### 5 嵌入（Embeddings）

电脑和人类处理单词的方式是不同的，所以你可以将数据编码成元素集，一个元素集可以理解为一个向量。

在这种情况下，一个向量包含一批数字，这些数字用来在多维空间映射元素间的关系。

当这些向量有了意义，我们称之为语义，而各个向量之间的距离可以衡量它们在语境中的关系。所以在这个场景下的向量被称为嵌入。

### 6 生成式 AI（Generative AI）

生成式 AI 是深度学习的一个子集，是一种可以创造出新内容和想法的人工智能，比如创造出对话、故事、图像、视频、音乐等。

和其他类型的 AI 一样，生成式 AI 也是基于机器学习模型的。这里的机器学习模型指的是基于海量数据预训练的大模型，也叫基础模型。

### 7 成式 AI 带来的“幻觉”（Hallucination）

生成式 AI 模型存在的一个问题就是它们有时会生成错误的内容却自信地传达给用户，这就是我们说的错觉。

### 8 神经网络（Neural Network）

神经网络是人工智能对于人类大脑处理信息过程的一种模仿，通过每层或者说“神经元”中的关联节点对数据进行学习，并随着时间推移不断提升性能。

神经网络使得计算机可以处理像图像和文字解读等复杂的任务，所以它在图像识别、语音转换文本、自然语言处理、以及个性化推荐等服务的实现中至关重要。

### 9 基础模型优化（Optimization） 

在 AI/ML 中，优化意味着通过调整超参数对模型进行微调以提高性能。

这些超参数属于外部配置变量，例如神经网络中的节点数量或学习率等超参数在模型训练开始之前就已设定。

使用贝叶斯优化或网格搜索等方法寻找这些超参数的最优值称为超参数调优

### 10 提示工程（ Prompt Engineering）

提示工程（Prompt Engineering）是**设计和精炼提示或输入激励以引导大型语言模型生成特定输出的过程**。

**这涉及谨慎选择关键字，提供上下文，以及在构建输入时，对模型要有具体的引导以使其产生期望的回复**。

无需通过微调复杂定制，通过提示工程即可控制模型的风格，语调和专业知识。在提示工程上预先投入精力，即便在未知数据或数据有限的情况下，模型生成也能表现良好

### 11 量化（Quantisation）

通常来说，量化涉及将连续值转化为离散值。连续值是你可以测量的东西，并且可以在一定区间内取任何值（例如，温度值可以是26.31°），

离散值则是孤立的点集（例如，海滩上的可卡犬的数量）。

在机器学习的背景下，量化在神经网络中发挥作用，此时它表示将权重和激活转换为低精度值。

这是一个重要的转换过程，特别是如果模型需要在内存有限的设备上运行，因为它可以帮助减少神经网络的内存要求、功耗和延迟

### 12 负责任的人工智能（Responsibility）

AI 中的责任是指在 AI 模型的开发和应用中持有的认知和道德原则，专注于公平性、有害性、真实性、隐私和知识产权等原则。

生成式 AI 的复杂性（可以生成一系列内容）在定义和执行道德原则上提出了特殊的挑战。

**开发负责任的 AI 的策略包括谨慎输入训练数据、开发防护模型以过滤不必要的内容，以及在各个领域持续合作以确保 AI 系统对所有用户都具备创新性、可靠性并尊重隐私**。

### 13 Amazon SageMaker

Amazon SageMaker 是亚马逊云科技提供的一项全面托管的机器学习服务，使数据科学家和开发者能够轻松构建、训练和部署 ML 模型。

它提供了一个集成的 Jupyter Notebook，用于数据探索、分析和模型开发，而无需管理服务器

### 14 ransformers 模型

Transformers 是一项在 2017 年的研究论文《注意力是你所需要的一切》（Attention Is All You Need）中提出的颠覆性技术。Transformer 架构是矩阵计算和神经网络的结合，其关键能力是将“注意力机制”应用到输入数据的相关部分。

Transformers 允许语言模型并行处理数据，并考虑句子的整个语境，而不仅仅是最后几个词。这些特性使 Transformers 能有效处理大量数据，对推动生成式 AI 的发展起到了关键作用，并形成了能执行复杂任务的大型语言模型的基础。

### 15 无监督学习（Unsupervised Learning）

**无监督学习是一种在无标签数据上训练的算法，输出时也没有对应的标签。它可以用于自主发现数据中的隐藏模式、关系和结构，且没有给定的目标值**。

应用包括将类似的内容进行聚类，如将新闻文章分类，或检测网络流量中的异常，即可能存在的安全漏洞。

无监督学习就像我去往一个新的城市，在没有地图指引的情况下，我会自己探索，找出地标、布局和城市中的商店模式，自主地进行探索。


相反，有监督学习是在有标记的数据上进行训练，**同时提供输入和对应的输出**。

**模型通过理解输入和期望输出之间的关系来进行预测或决策。**

例如，利用楼盘位置和房间数量等特征来预测房屋价格，或从标记过的数字图像中识别手写数字。有监督学习就像对着参考答案做作业一样——问题（输入数据）和答案（输出标签）都已提供，所以你可以通过看问题和答案来学习。一旦一个模型（或者说学生）经过有监督学习训练，他们可以对新的未见过的数据做出预测，就像在考试中考到类似的题目一样。

### 16 向量数据库（Vector Databases）

向量数据库是一种专用数据库，支持存储和检索代表各种类型数据的高维向量。

**它可以用于在 N 维空间中有效和快速地查找最近邻，因此对于语义搜索、向量搜索和多模态搜索等任务非常有用。**

向量数据库在生成式 AI 应用的背后起着关键作用，因为它们可以支持定制语言模型，提高准确性，并为对话式搜索或根据文本提示生成图像等独特的用户体验提供基础。

### 17 模型权重（Weights）

权重是神经网络中使用的数值，用于确定神经元之间连接的强度

### 18 可解释 AI（XAI）

可解释的人工智能（通常简称为 XAI）对于建立对 AI 系统的信任和信心至关重要，特别是当 AI 做出的决策可能产生重大后果时。

可解释性有两个关键方面：**可诠释性和可解释性**。

可诠释性意味着理解 AI 模型的内部工作机制，如权重和特征，以理解如何生成预测及其原因。另一方面，可解释性使用与模型无关的方法来用人类的语言描述 AI 模型的行为，即使对于“黑箱”模型也是如此。

一个模型注重可诠释性还是可解释性，取决于具体的使用案例、数据类型和业务需求，这可能涉及在实现高性能和保持解释模型行为的能力之间进行权衡。

