# 1 Introduction to Developing AI Agents

## 2 Understanding Fundamental Concepts of AI Agents


Here's a concise summary of the key points about AI agents from the provided text:

1.  **Definition:** An AI agent is an entity that perceives its environment (physical or digital) through sensors and acts upon that environment using effectors (per ISO definition).


2.  **Core Components:**
    *   **Sensors:** Gather raw data (percepts) from the environment (e.g., cameras, microphones, API calls).
    *   **Control Center:** The "brain" processes percepts, makes decisions, and plans actions (often using an LLM).
    *   **Effectors/Actuators:** Carry out actions to change the environment (e.g., moving an arm, updating a database, generating a report).
    *   **Environment:** The world (physical or digital) the agent operates within.
    *   **User Input:** External input provided (e.g., commands, data) usually by humans or other agents.
    *   **Percepts:** Raw data inputs from sensors.
    *   **Actions:** Changes made in the environment by effectors.


**An agent is anything that can perceive its environment and act upon that environment.**

![Alt Image Text](../images/chap8_1_1.png "Body image")

## Exploring Different Types of AI Agents 

**Types of AI Agents**

* Simple reflex agents
* Model-based reflex agents
* Goal-based agents
* Learning agents

**Simple Reflex Agents** and **Model-Based Reflex Agents**:

### 1.  **Simple Reflex Agents:**

*   **Operation:** React *only* to current percepts (immediate inputs) with no memory of past events.
*   **Requirement:** Work best in **fully observable** environments.
*   **Mechanism:** Follow predefined `condition -> action` rules.
*   **Limitations:**
  *   Cannot learn, adapt, reason, or handle unobservable aspects.
  *   Require increasingly complex rule sets for complex environments (hard to scale/maintain).
*   **Example:** A thermostat turning on heat *only* if current temp < 10Â°C (fails if a window is open).
*   **Use Cases:** Basic spam filters (keyword matching), simple automated email responders.

> Simple Reflex Agent

![Alt Image Text](../images/chap8_1_2.png "Body image")

Simple reflex agents make decisions based only on current percepts, ignoring history

They work only in fully observable environments

They follow Condition-action rules

- Limited intelligence.
- No knowledge of non-perceptual state aspects.
- Often too large to generate/store.
- Not adaptive to environmental changes

### 2.  **Model-Based Reflex Agents:**


![Alt Image Text](../images/chap8_1_3.png "Body image")

**Model-based agents work in partially observable environments and track situations**

They have two key factors:

- **Model**: Knowledge of how the world works

- **Internal State**: Representation of the current state based on percept history

These agents use their model to make decisions

Updating state requires knowing:

- How the world evolves
- How the agentâ€™s actions affect the world

*   **Operation:** React to current percepts *and* maintain an **internal state** based on past percepts (memory).
*   **Core Components:**
  *   **Model:** Knowledge of "how the world works" (e.g., how actions change the environment).
  *   **Internal State:** Representation of the current world state based on percept history.
*   **Advantage:** More adaptable than simple reflex agents; can handle **partially observable** environments.
*   **Mechanism:** Still use `condition -> action` rules, but conditions can include the internal state.
*   **State Update:** Relies on the model to understand world evolution and action effects.
*   **Use Cases:** Smart thermostats (using history & preferences), smart robotic vacuums (using sensor maps).

### **Key Differences Summarized:**

| Feature          | Simple Reflex Agent        | Model-Based Reflex Agent       |
| :--------------- | :------------------------- | :----------------------------- |
| **Memory**       | None                       | Yes (Internal State)           |
| **Observability**| Requires Full              | Handles Partial                |
| **Adaptability** | None (Rigid Rules)         | Higher (Uses Model & State)    |
| **Complexity**   | Rules bloat in complex env | More complex internally        |
| **Example**      | Basic Thermostat           | Learning Thermostat / Smart Vacuum |

Here's a concise summary of **Goal-Based Agents** and **Learning Agents**:

### 3 **Goal-Based Agents**

- Knowing the current state is not always enough for decision-making 
- Agents need a goal to define desirable outcomes 
- Goal-based agents enhance model-based agents with goal information 
- They select actions to achieve their goal 
- They evaluate action sequences through searching and planning, making them proactive


![Alt Image Text](../images/chap8_1_4.png "Body image")


1.  **Core Function:**  
    *   Plan sequences of actions to achieve **specific goals** (desirable future states).  
    *   Extend model-based agents by incorporating goal information.  
2.  **Key Mechanism:**  
    *   **Searching & Planning:** Evaluate future scenarios to choose actions leading toward the goal.  
    *   **Proactive:** Focus on long-term outcomes rather than immediate reactions.  
3.  **Examples:**  
    *   **Chess AI:** Plans moves to win by evaluating long-term strategies.  
    *   **Logistics Route Optimization:** Plans efficient delivery paths based on priorities (e.g., fuel/time).  

---

### **4 Learning Agents**


![Alt Image Text](../images/chap8_1_5.png "Body image")

A learning agent improves by learning from past experiences

It has four main components:

* **Learning element**: Improves by interacting with the environment
* Critic: Provides feedback on performance.
* Performance element: Selects external actions.
* **Problem generator**: Suggests actions for new experiences.

**Learning agents analyze performance and seek improvements.**


1.  **Core Function:**  
    *   Continuously **adapt and improve** performance through experience.  
    *   Start with basic knowledge and refine over time.
       
2.  **Key Components:**


    | **Component**       | **Role**                                                                 |  
    |---------------------|--------------------------------------------------------------------------|  
    | **Learning Element** | Improves knowledge/behavior based on environmental feedback.            |  
    | **Critic**          | Evaluates performance against a fixed standard (provides feedback).     |  
    | **Performance Element** | Executes actions (e.g., the agentâ€™s decision-making module).          |  
    | **Problem Generator** | Suggests exploratory actions to gain new, informative experiences.   |  

3.  **Examples:**  
    *   **Recommendation Systems (Netflix/Amazon):** Learn user preferences to refine suggestions.  
    *   **Adaptive Thermostats:** Learn user habits (e.g., schedule, temperature preferences) to auto-adjust.  


## 3 Understanding Advanced AI Agents

* Leverage LLMs as a reasoning engine
* Use a language model to plan actions


1.  **Core Engine:** Rely on **LLMs (Large Language Models)** or **LMMs (Large Multimodal Models)** as their reasoning engine to plan and execute action sequences for achieving goals.

**Key Components of Advanced AI Agents**

![Alt Image Text](../images/chap8_1_6.png "Body image")

2.  **Frameworks:** Built using popular frameworks/tools like **LangGraph, CrewAI, OpenAI's Swarm, Microsoft's AutoGen**, and others.

3.  **Control Center:**
    *   **Input Director:** Routes user input to the core model.
    *   **Core Model:** The LLM/LMM that processes input and generates outcomes.
    *   **Orchestrator:** Manages the overall system workflow and autonomy


4.  **Agentic AI:** Systems designed to **act autonomously** towards goals. "Agentic" describes the degree of agent-like qualities on a continuum (flexible categorization).

**The Spectrum of Agentic Systems**

1. Not an agent
2. Rule based
3. ML models
4. Adaptive AI
5. Autonomous

The concept of agentic represents a spectrum of agent-like qualities

5. Agentic AI Design Patterns

**Reflection (RL)**: Agents that can analyze their own outputs and identify areas of improvement

**Tool use:** Agents that can access and utilize tools to enhance their capabilities

**Planning and reasoning**: Agents that can think ahead, consider multiple options, and make informed decisions

**Multi-agent collaboration:** Multiple agents working together to solve complex problems

**Memory management:** Agents that can retain important context and history from past interactions

## 4 Introduction to LangGraph


### **LangGraph Implementation**

Using LangGraph to Create Agentic System for Shop Hours Inquiry

- LangGraph introduced by LangChain

- With LangGraph you can create highly controllable agents

1. **Library Overview**:


   - Stateful multi-actor application builder by LangChain creators  
   - Models workflows as **graphs** with three core components:

     - **State**: Shared data structure that represents the current snapshot (e.g., conversation history)
     
     - **Nodes**: Python functions handling logic of your agents (e.g., process input, call LLMs)
       
     - **Edges**: Python functions that determine which Node to execute next (decide next node based on state)  

3. **Workflow Setup (VS Code/Jupyter)**:  
   - **Dependencies**: Installed `langchain`, `langgraph`, OpenAI integration  
   - **LLM Setup**: Initialized `ChatOpenAI` with `gpt-3.5-turbo`  
   - **State Definition**: Used `MessageState` to store conversation history  
   - **Node Creation**:  
     - Defined `assistant_node` to process user queries + system prompts  
   - **Graph Assembly**:  
     - Added start â†’ assistant â†’ end nodes  
     - Compiled into runnable workflow  
     - Visualized graph structure  

ä¸‹é¢æ˜¯å®Œæ•´çš„ä¸­æ–‡ç¿»è¯‘ï¼š

---

### **ä½¿ç”¨ LangGraph æ„å»ºå•†åº—è¥ä¸šæ—¶é—´æŸ¥è¯¢çš„æ™ºèƒ½ä»£ç†ç³»ç»Ÿ**

* **LangGraph** ç”± **LangChain** æ¨å‡º
* ä½¿ç”¨ LangGraph å¯ä»¥åˆ›å»º **é«˜åº¦å¯æ§çš„æ™ºèƒ½ä»£ç†ï¼ˆAgentï¼‰**

---

**1. åº“æ¦‚è¿°ï¼ˆLibrary Overviewï¼‰ï¼š**

* ç”± LangChain å›¢é˜Ÿå¼€å‘çš„ **æœ‰çŠ¶æ€ï¼ˆstatefulï¼‰å¤šæ™ºèƒ½ä½“åº”ç”¨æ„å»ºå·¥å…·**
* ä½¿ç”¨ **å›¾ç»“æ„ï¼ˆgraphï¼‰** æ¥æè¿°å·¥ä½œæµç¨‹ï¼ŒåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š

#### **Stateï¼ˆçŠ¶æ€ï¼‰**

* å…±äº«çš„æ•°æ®ç»“æ„
* ç”¨æ¥è¡¨ç¤ºå½“å‰ç³»ç»Ÿçš„å¿«ç…§ï¼ˆä¾‹å¦‚ï¼šå¯¹è¯å†å²ï¼‰

####  **Nodesï¼ˆèŠ‚ç‚¹ï¼‰**

* Python å‡½æ•°
* ç”¨æ¥å¤„ç†ä»£ç†çš„é€»è¾‘ï¼ˆä¾‹å¦‚ï¼šå¤„ç†è¾“å…¥ã€è°ƒç”¨ LLM ç­‰ï¼‰

####  **Edgesï¼ˆè¾¹ï¼‰**

* Python å‡½æ•°
* ç”¨æ¥å†³å®šä¸‹ä¸€ä¸ªè¦æ‰§è¡Œçš„èŠ‚ç‚¹
* æ ¹æ®å½“å‰ State å†³ç­–æµç¨‹èµ°å‘

---

####  **3. å·¥ä½œæµç¨‹è®¾ç½®ï¼ˆVS Code / Jupyterï¼‰**

* **ä¾èµ–å®‰è£…**ï¼šå®‰è£… `langchain`ã€`langgraph`ã€OpenAI é›†æˆåº“
* **LLM è®¾ç½®**ï¼šåˆå§‹åŒ– `ChatOpenAI` ä½¿ç”¨ `gpt-3.5-turbo`
* **State å®šä¹‰**ï¼šä½¿ç”¨ `MessageState` ä¿å­˜å¯¹è¯å†å²
* **èŠ‚ç‚¹åˆ›å»ºï¼ˆNode Creationï¼‰**ï¼š

  * åˆ›å»º `assistant_node` ç”¨æ¥å¤„ç†ç”¨æˆ·é—®é¢˜å’Œ system prompt
* **å›¾ç»“æ„æ„å»ºï¼ˆGraph Assemblyï¼‰**ï¼š

  * æ·»åŠ  `start â†’ assistant â†’ end`
  * ç¼–è¯‘ä¸ºå¯è¿è¡Œçš„å·¥ä½œæµç¨‹
  * å¯è§†åŒ–å›¾ç»“æ„


4. **Demo Execution**:  
   - Tested query: *"What is the capital of Sweden?"* â†’ Correctly returned *"Stockholm"*

```
pip install -quit langchain_openai langchain_core langgraph

pip install --upgrade langchain langgraph
```

```
from langchain_openai import ChatOpenAI

llm = ChatOpenAI(
    model="gpt-oss:20b",  # Or the name of the model you downloaded in Ollama
    openai_api_base="http://localhost:11434/v1", # Ollama's API base
    api_key="not-needed"  # LM Studio does not require an API key
)
```


```
from langgraph.graph import MessagesState
from langchain_core.messages import HumanMessage, SystemMessage

sys_msg = SystemMessage(content="You are a helpful assistant to respond to general purpose queries.")

def assistant(state: MessagesState):
    return {"messages": [llm.invoke([sys_msg]+ state["messages"])]}
```

```
from langgraph.graph import START, StateGraph, END
from IPython.display import Image, display

builder = StateGraph(MessagesState)
builder.add_node("assistant", assistant)

builder.add_edge(START, "assistant")
builder.add_edge("assistant", END)

react_graph = builder.compile()
display(Image(react_graph.get_graph(xray=True).draw_mermaid_png(max_retries=5, retry_delay=2.0)))
```

![Alt Image Text](../images/chap8_1_7.png "Body image")

```
messages = [HumanMessage(content="Tell me what is the capital of Sweden?")]
messages = react_graph.invoke({"messages" : messages})

for m in messages ['messages']: 
    m.pretty_print()
```

```
messages = [HumanMessage(content="Tell me what is the capital of Sweden?")]
messages = react_graph.invoke({"messages" : messages})

for m in messages ['messages']: 
    m.pretty_print()
```

### **Key Limitation & Next Step**

- **Problem**: LLMs lack real-time data (e.g., store hours/returns policy).  
- **Solution**: **Tool calling** to integrate APIs/databases (next section).

**CrewAIâ€™s Key Components** 

CrewAI helps you create an organization of AI agents with specialized roles collaborating to accomplish complex tasks.

**Agent**

An autonomous entity that performs tasks and utilizes tools

**Task**

A specific assignment completed by an Agent

**Crew**

A team of agents collaborating to complete tasks

#### **Implementation Flow**

```mermaid
graph LR
A[Define State] --> B[Create Nodes]
B --> C[Add Edges]
C --> D[Compile Graph]
D --> E[Execute Queries]
E --> F[Integrate Tools]
```

**Essence**: LangGraph enables building stateful agent workflows for Carved Rock's needs, starting with simple Q&A and extending to real-time tool integration.


### With deepseek

```
%%capture --no-stderr

pip install -U langchain-core langchain-community langchain-openai langgraph
```

```
from langchain_openai import ChatOpenAI

# Use your local DeepSeek model running in Ollama
llm = ChatOpenAI(
    model="deepseek-r1:1.5b",      # or deepseek-coder..., deepseek-r1, etc.
    openai_api_base="http://localhost:11434/v1",
    api_key="not-needed",         # Ollama does not require a key
    # verbose=True
)
```

```
from langgraph.graph import MessagesState
from langchain_core.messages import HumanMessage, SystemMessage

sys_msg = SystemMessage(content="You are a helpful assistant to respond to general purpose queries.")

def assistant(state: MessagesState):
    return {"messages": [llm.invoke([sys_msg] + state["messages"])]}
```

```
from langgraph.graph import START, StateGraph, END
from IPython.display import Image, display

builder = StateGraph(MessagesState)
builder.add_node("assistant", assistant)

builder.add_edge(START, "assistant")
builder.add_edge("assistant", END)

react_graph = builder.compile()
display(Image(react_graph.get_graph(xray=True).draw_mermaid_png(max_retries=5, retry_delay=2.0)))
```

![Alt Image Text](../images/chap8_1_7.png "Body image")

```
messages = [HumanMessage(content="Tell me what is the capital of Sweden?")]

result = react_graph.invoke({"messages": messages})

for m in result["messages"]:
    m.pretty_print()
```

```
================================[1m Human Message [0m=================================

Tell me what is the capital of Sweden?
==================================[1m Ai Message [0m==================================

<think>
Alright, I need to figure out the capital of Sweden. Let's see... The user has asked for that specific information.

First, I should think about where capitals are often located. Usually, they are major cities. In Sweden, I'm pretty sure Carlsberg is a big city but didn't it get merged with another place? Maybe it was previously part of Gothenburg?

I remember reading that during their unification period, the capital was called "Gothenburg," but over time it became known as Carlsberg. That makes sense because it's a common city name in Sweden and still used today.

Also, when I did some quick research before, yes, the capital was Carlsberg after the merger. So that's probably the correct answer for the user.
</think>

The capital of Sweden is **Carlsberg** after its city has been renamed to honor Carl BernÃ¶glie, the former capital from 1735 to 1906. Though it became officially known as Carlsberg until 1852 when it was part of Gothenburg (Gothenburg being a city near MalmÃ¶), as the user suggested, Carlsberg remains the current capital.
```


## Using LangGraph with Tool Calling to Create Agentic Workflow for Shop Hours Inquiry


âœ… **Summary**

The article explains how to build a **multi-agent system** using LangGraph, where different specialized agents collaborate to answer user queries. Instead of relying on a single general-purpose agent with many tools, it is recommended to create **multiple specialized agents**, each responsible for a specific task and equipped with its own tools.

A **supervisor agent** (also an LLM-driven agent) is used to analyze user input and determine which specialized agent should handle each subtask.

The demo uses LangGraphâ€™s pre-built agent architectures:

### **1. Specialized Agents**

Two agents are created using `create_react_agent`:

* **time_keeper_agent**

  * Uses a tool that returns the current date and time
  * Has its own system prompt and model

* **schedule_keeper_agent**

  * Uses a tool that provides the shopâ€™s opening hours
  * Also has its own prompt and model

These agents operate independently and handle only their specific responsibilities.

### **2. Supervisor Agent**

A supervisor is created using `create_supervisor`:

* Manages communication between agents
* Routes tasks to the correct agent
* Uses the system prompt to decide when to call each agent
* Adds messages to conversation state with `output_mode`

### **3. Workflow Execution**

The compiled supervisor graph is tested with a combined question:

* *What are the shopâ€™s weekend hours?*
* *Is the shop open now?*

The supervisor coordinates both agents:

* Calls the schedule agent for weekend hours
* Calls the time agent for the current time

The final response correctly determines the weekend hours and concludes that the shop is closed based on the current time (Saturday, 8:27 PM).

---

â­ **Key Takeaway**

LangGraph makes it easy to build **hierarchical multi-agent systems** with:

* Specialized agents
* Tool-based actions
* A supervisor that orchestrates them

------


ä¸‹é¢æ˜¯ä¸Šè¿°æ€»ç»“çš„ **ä¸­æ–‡ç¿»è¯‘ç‰ˆ**ï¼š

---


æ–‡ç« ä»‹ç»äº†å¦‚ä½•ä½¿ç”¨ LangGraph æ„å»ºä¸€ä¸ª **å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**ï¼Œè®©å¤šä¸ªä¸“é—¨ä»£ç†åä½œå›ç­”ç”¨æˆ·é—®é¢˜ã€‚ä¸å…¶ä½¿ç”¨ä¸€ä¸ªæ‹¥æœ‰æ‰€æœ‰å·¥å…·çš„é€šç”¨å‹å¤§ä»£ç†ï¼Œæ›´æ¨èåˆ›å»º **å¤šä¸ªå„å¸å…¶èŒçš„ä¸“é—¨ä»£ç†ï¼ˆspecialized agentsï¼‰**ï¼Œæ¯ä¸ªä»£ç†åªå¤„ç†ç‰¹å®šä»»åŠ¡å¹¶ä½¿ç”¨ä¸“å±å·¥å…·ã€‚

ä¸€ä¸ª **ç›‘ç£ä»£ç†ï¼ˆsupervisor agentï¼‰** ä¼šè´Ÿè´£åˆ†æç”¨æˆ·è¾“å…¥ï¼Œå¹¶å†³å®šå°†æ¯ä¸ªå­ä»»åŠ¡åˆ†é…ç»™å“ªä¸ªä¸“é—¨ä»£ç†ã€‚ç›‘ç£ä»£ç†æœ¬èº«ä¹Ÿæ˜¯ä¸€ä¸ª LLM ä»£ç†ã€‚

åœ¨ç¤ºä¾‹ä¸­ï¼Œä½œè€…ä½¿ç”¨ LangGraph å·²é¢„æ„å»ºçš„ä»£ç†æ¶æ„ï¼š

---

### **1. ä¸“é—¨ä»£ç†ï¼ˆSpecialized Agentsï¼‰**

ä½¿ç”¨ `create_react_agent` åˆ›å»ºäº†ä¸¤ä¸ªä»£ç†ï¼š

#### **time_keeper_agentï¼ˆæ—¶é—´ä»£ç†ï¼‰**

* ä½¿ç”¨ä¸€ä¸ªâ€œè¿”å›å½“å‰æ—¥æœŸæ—¶é—´â€çš„å·¥å…·
* æ‹¥æœ‰ç‹¬ç«‹çš„ system prompt å’Œæ¨¡å‹

#### **schedule_keeper_agentï¼ˆè¥ä¸šæ—¶é—´ä»£ç†ï¼‰**

* ä½¿ç”¨ä¸€ä¸ªâ€œè¿”å›å•†åº—è¥ä¸šæ—¶é—´è¡¨â€çš„å·¥å…·
* åŒæ ·æœ‰è‡ªå·±çš„ prompt å’Œæ¨¡å‹

è¿™ä¸¤ä¸ªä»£ç†äº’ä¸å¹²æ‰°ï¼Œå„è‡ªå¤„ç†è‡ªå·±çš„ä»»åŠ¡ã€‚

---

### **2. ç›‘ç£ä»£ç†ï¼ˆSupervisor Agentï¼‰**

é€šè¿‡ `create_supervisor` åˆ›å»ºï¼š

* ç®¡ç†æ‰€æœ‰ä»£ç†ä¹‹é—´çš„æ²Ÿé€š
* æ ¹æ®ç”¨æˆ·é—®é¢˜è‡ªåŠ¨é€‰æ‹©éœ€è¦è°ƒç”¨çš„ä»£ç†
* é€šè¿‡ system prompt è®¾å®šæ‰§è¡Œè§„åˆ™
* é€šè¿‡ `output_mode` æ§åˆ¶æ¶ˆæ¯å¦‚ä½•å†™å…¥çŠ¶æ€

---

### **3. æ‰§è¡Œå·¥ä½œæµç¨‹**

æµ‹è¯•æ—¶è¾“å…¥äº†ä¸¤ä¸ªåˆå¹¶çš„é—®é¢˜ï¼š

* å•†åº—å‘¨æœ«çš„è¥ä¸šæ—¶é—´æ˜¯å¤šå°‘ï¼Ÿ
* ç°åœ¨å•†åº—æœ‰å¼€å—ï¼Ÿ

ç›‘ç£ä»£ç†è‡ªåŠ¨è°ƒç”¨ï¼š

* è¥ä¸šæ—¶é—´ä»£ç† â†’ è·å–å‘¨æœ«è¥ä¸šæ—¶é—´
* æ—¶é—´ä»£ç† â†’ è·å–å½“å‰æ—¶é—´

æœ€ç»ˆï¼Œç³»ç»Ÿæ­£ç¡®å¾—å‡ºï¼š

* å‘¨æœ«è¥ä¸šæ—¶é—´
* å½“å‰ï¼ˆå‘¨å…­æ™šä¸Š 8:27ï¼‰å•†åº—å·²ç»æ‰“çƒŠ

---

â­ **å…³é”®ç»“è®º**

LangGraph èƒ½å¤Ÿè½»æ¾æ­å»º **å±‚çº§å¼å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ**ï¼Œå…·æœ‰ï¼š

* ä¸“èŒä»£ç†
* å·¥å…·é©±åŠ¨åŠ¨ä½œ
* ç›‘ç£ä»£ç†åè°ƒè§’è‰²

è®©ç³»ç»Ÿæ›´åŠ æ¨¡å—åŒ–ã€æ›´æ˜“ç»´æŠ¤ã€æ›´å‡†ç¡®ã€‚

```
%%capture --no-stderr
pip install -quit langchain_openai langchain_core langgraph
```

```
from langchain_openai import ChatOpenAI
import datetime

llm = ChatOpenAI(
    model="gpt-oss:20b",  # Or the name of the model you downloaded in Ollama
    openai_api_base="http://localhost:11434/v1", # Ollama's API base
    api_key="not-needed"  # LM Studio does not require an API key
)

def shopopeninghours () -> str:
    "This tool provides the daily opening hours schedule for a shop."
    schedule = """Monday 10:00am to 08:00pm
                  Tuesday 10:00am to 08:00pm 
                  Wednesday 10:00am to 08:00pm
                  Thursday 10:00am to 08:00pm 
                  Friday 10:00am to 08:00pm
                  Saturday 11:00am to 05:00pm 
                  Sunday 1:00pm to 06:00pm"""
    return schedule

def Currenttime() -> datetime:
    "This tool provides the current date and time." 
    return datetime.datetime.now()

tools = [shopopeninghours,Currenttime]

llm_with_tools = llm.bind_tools(tools)
```

```
from langgraph.graph import MessagesState
from langchain_core.messages import HumanMessage, SystemMessage

sys_msg = SystemMessage(content="""
                    You are a helpful assistant responsible
                    for determining whether a shop is open or closed
                    based on the current time and the shop's opening schedule.""")
      
def assistant(state: MessagesState):
    return {"messages": [llm_with_tools.invoke([sys_msg]+ state["messages"])]}
```

```
from langgraph.graph import START, StateGraph
from langgraph.prebuilt import tools_condition
from langgraph.prebuilt import ToolNode
from IPython.display import Image, display

builder = StateGraph(MessagesState)

builder.add_node("assistant", assistant)
builder.add_node("tools", ToolNode(tools))

builder.add_edge(START, "assistant")
builder.add_conditional_edges("assistant", tools_condition)
builder.add_edge("tools", "assistant")

react_graph = builder.compile()

display(Image(react_graph.get_graph(xray=True).draw_mermaid_png(max_retries=5, retry_delay=2.0)))
```


![Alt Image Text](../images/chap8_1_8.png "Body image")


```
messages = [HumanMessage(content="Tell me if the shop is open right now?")]
messages = react_graph.invoke({"messages" : messages})

for m in messages ['messages']: 
    m.pretty_print()
```

```
================================[1m Human Message [0m=================================

Tell me if the shop is open right now?
==================================[1m Ai Message [0m==================================
Tool Calls:
  Currenttime (call_p7bhcmyy)
 Call ID: call_p7bhcmyy
  Args:
=================================[1m Tool Message [0m=================================
Name: Currenttime

2025-11-16 11:24:46.089065
==================================[1m Ai Message [0m==================================
Tool Calls:
  shopopeninghours (call_ytsmpjt6)
 Call ID: call_ytsmpjt6
  Args:
    date: 2025-11-16T11:24:46+01:00
=================================[1m Tool Message [0m=================================
Name: shopopeninghours

Monday 10:00am to 08:00pm
                Tuesday 10:00am to 08:00pm 
                Wednesday 10:00am to 08:00pm
                Thursday 10:00am to 08:00pm 
                Friday 10:00am to 08:00pm
                Saturday 11:00am to 05:00pm 
                Sunday 1:00pm to 06:00pm
==================================[1m Ai Message [0m==================================

The shop's opening hours are from 10:00 AM to 08:00 PM on Monday through Friday, from 11:00 AM to 05:00 PM on Saturdays, and from 01:00 PM to 06:00 PM on Sundays.

According to the current time (2025-11-16 11:24:46), which is within the range of Monday's opening hours, the shop is currently **open**.
```

## Learning about Al Agents, Their types, and Architecture Using Real-world Demos



**CrewAI** is an open-source framework for building multi-agent systems, referred to as "crews." A crew is a team of specialized AI agents that collaborate to complete complex tasks.

### Core Concepts:

*   **Agent:** An autonomous unit with a specific role, goal, and backstory that performs tasks using tools.
*   **Task:** A specific assignment for an agent, defined by a description, expected output, and an assigned agent.
*   **Crew:** A group of agents that work together, defining the strategy for task execution and collaboration.

### Key Features & Implementation:

*   **Model Flexibility:** Uses **LiteLLM**, allowing seamless switching between over 100 different language models (default is OpenAI's GPT-4).
*   **Configuration via YAML:** Agents and tasks are typically configured in YAML files, specifying their roles, goals, and backstories.
*   **Dynamic Inputs:** Uses placeholders in configuration files (e.g., `topic`) that are filled with values when the crew is run.
*   **Task Execution:** Supports two methods:
    *   **Sequential:** Tasks run one after another.
    *   **Hierarchical:** A manager agent dynamically assigns tasks.
*   **Output Options:** Tasks can be configured to save their output directly to a file.

æ ¹æ®æ–‡ç« å†…å®¹ï¼Œä»¥ä¸‹æ˜¯ CrewAI æ¡†æ¶çš„æ€»ç»“ï¼š

**CrewAI** æ˜¯ä¸€ä¸ªç”¨äºæ„å»ºå¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å¼€æºæ¡†æ¶ï¼Œè¯¥ç³»ç»Ÿè¢«ç§°ä¸ºâ€œå›¢é˜Ÿâ€ã€‚ä¸€ä¸ªå›¢é˜Ÿæ˜¯ç”±ä¸“é—¨çš„äººå·¥æ™ºèƒ½æ™ºèƒ½ä½“ç»„æˆçš„ï¼Œå®ƒä»¬ç›¸äº’åä½œä»¥å®Œæˆå¤æ‚ä»»åŠ¡ã€‚

### æ ¸å¿ƒæ¦‚å¿µï¼š

*   **æ™ºèƒ½ä½“ï¼š** ä¸€ä¸ªå…·æœ‰ç‰¹å®šè§’è‰²ã€ç›®æ ‡å’ŒèƒŒæ™¯çš„è‡ªä¸»å•å…ƒï¼Œèƒ½å¤Ÿä½¿ç”¨å·¥å…·æ‰§è¡Œä»»åŠ¡ã€‚
*   **ä»»åŠ¡ï¼š** åˆ†é…ç»™æ™ºèƒ½ä½“çš„å…·ä½“å·¥ä½œï¼Œé€šè¿‡æè¿°ã€é¢„æœŸè¾“å‡ºå’ŒæŒ‡å®šçš„æ™ºèƒ½ä½“æ¥å®šä¹‰ã€‚
*   **å›¢é˜Ÿï¼š** ä¸€ç»„å…±åŒåä½œçš„æ™ºèƒ½ä½“ï¼Œå®šä¹‰äº†ä»»åŠ¡æ‰§è¡Œå’Œåä½œçš„ç­–ç•¥ã€‚

### ä¸»è¦ç‰¹æ€§ä¸å®ç°ï¼š

*   **æ¨¡å‹çµæ´»æ€§ï¼š** ä½¿ç”¨ **LiteLLM**ï¼Œå…è®¸åœ¨è¶…è¿‡ 100 ç§ä¸åŒçš„è¯­è¨€æ¨¡å‹ä¹‹é—´æ— ç¼åˆ‡æ¢ï¼ˆé»˜è®¤ä¸º OpenAI çš„ GPT-4ï¼‰ã€‚
*   **é€šè¿‡ YAML é…ç½®ï¼š** æ™ºèƒ½ä½“å’Œä»»åŠ¡é€šå¸¸åœ¨ YAML æ–‡ä»¶ä¸­è¿›è¡Œé…ç½®ï¼ŒæŒ‡å®šå…¶è§’è‰²ã€ç›®æ ‡å’ŒèƒŒæ™¯æ•…äº‹ã€‚
*   **åŠ¨æ€è¾“å…¥ï¼š** åœ¨é…ç½®æ–‡ä»¶ä¸­ä½¿ç”¨å ä½ç¬¦ï¼ˆä¾‹å¦‚ `topic`ï¼‰ï¼Œè¿™äº›å ä½ç¬¦åœ¨è¿è¡Œå›¢é˜Ÿæ—¶ä¼šè¢«å¡«å…¥å…·ä½“å€¼ã€‚
*   **ä»»åŠ¡æ‰§è¡Œï¼š** æ”¯æŒä¸¤ç§æ–¹æ³•ï¼š
    *   **é¡ºåºæ‰§è¡Œï¼š** ä»»åŠ¡ä¸€ä¸ªæ¥ä¸€ä¸ªåœ°è¿è¡Œã€‚
    *   **åˆ†å±‚æ‰§è¡Œï¼š** ä¸€ä¸ªç®¡ç†å‹æ™ºèƒ½ä½“åŠ¨æ€åœ°åˆ†é…ä»»åŠ¡ã€‚
*   **è¾“å‡ºé€‰é¡¹ï¼š** å¯ä»¥é…ç½®ä»»åŠ¡å°†å…¶è¾“å‡ºç›´æ¥ä¿å­˜åˆ°æ–‡ä»¶ä¸­ã€‚

